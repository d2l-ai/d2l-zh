

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-02 18:37:33
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-02 18:52:59
 * @Description:translate AutoRec
 * @TODO::
 * @Reference:http://preview.d2l.ai/d2l-en/PR-1092/chapter_recommender-systems/autorec.html
-->

# 自动录制: 使用自动编码器进行评级预测

尽管矩阵分解模型在评级预测任务上取得了不错的表现，但它本质上是一个线性模型。 因此，这样的模型不能捕捉复杂的非线性和复杂的关系，这些关系可以预测用户的偏好。 在这一节中，我们介绍一个非线性神经网络 / 协同过滤模型，AutoRec [ Sedhain et al. ，2015](http://preview.d2l.ai/d2l-en/PR-1092/chapter_references/zreferences.html#sedhain-menon-sanner-ea-2015)。 它用一个自动编码器结构来识别协同过滤，目的是在显式反馈的基础上将非线性变换集成到自动编码器中。 神经网络已经被证明能够逼近任何连续函数，使它适合于解决矩阵分解的局限性和丰富矩阵分解的表达能力。

一方面，AutoRec 具有与自动编码器相同的结构，它由输入层、隐藏层和重构(输出)层组成。 自动编码器是一种神经网络，它学习将输入复制到输出，以便将输入编码到隐藏(通常是低维)表示中。 在 AutoRec 中，它不是显式地将用户 / 项嵌入到低维空间，而是使用交互矩阵的列 / 行作为输入，然后在输出层重新构造交互矩阵。

另一方面，AutoRec 不同于传统的自动编码器: AutoRec 关注于学习 / 重构输出层，而不是学习隐藏表示。 它使用部分观察到的交互矩阵作为输入，旨在重建一个完整的评级矩阵。 同时，为了推荐的目的，通过重构在输出层中填补输入的缺失项。

Autorec 有两个变体: 基于用户的和基于项目的。 为了简短起见，这里我们只介绍基于项的自动记录。 可以相应地派生出基于用户的 AutoRec。

## 模型


设$R_*i$表示评级矩阵的$i^th$列，其中未知评级默认为零。
神经结构被定义为:

TODO:MATH

其中 f (·) 和 g(·)代表激活函数，$W$ 和 $V$代表权重矩阵，$μ$和$b$代表偏差。 设 h (·) 表示 AutoRec 的整个网络。 输出TODO:MATH$h (R_*i)$是评分矩阵第 i 列的重构。

以下目标函数旨在最小化重构误差:

TODO:MATH

这里面，仅仅考虑了观测值的作用，即只更新了与观测值相关联的权系数。

## 实现模型

典型的自动编码器由编码器和解码器组成。 编码器将输入投影到隐藏表示，解码器将隐藏层映射到重构层。 我们按照这种做法，并创建了密集层（dense layers）的编码器和解码器。 编码器的激活默认设置为 sigmoid，解码器不激活。 在编码转换之后包括dropout，以减少过度拟合。 未观测输入的梯度被掩盖，以确保只有观测到的评分有助于模型学习过程。

TODO:CODE

## 训练和评估模型

现在，让我们在MovieLens数据集上训练和评估AutoRec。我们可以清楚地看到，测试RMSE低于矩阵分解模型，证实了神经网络在评级预测任务中的有效性。

TODO：CODE

## 总结

- 在积分非线性层和遗漏正则化的同时，我们可以用自动编码器构造矩阵分解算法。
- 在MovieLens 100K数据集上的实验表明，AutoRec的性能优于矩阵分解。

## 练习

1. 改变AutoRec的隐藏维度，看看它对模型性能的影响。
2. 尝试添加更多的隐藏层。是否有助于提高模型性能?
3. 你能找到一个更好的解码器和编码器激活功能的组合吗
